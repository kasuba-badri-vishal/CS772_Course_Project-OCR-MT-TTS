DISCONTINUOUS PIECEWISE POLYNOMIAL NEURAL NETWORKS Table 2: Maximum overshoot fraction, pnmax, given the number of points in the polynomial interpolation . 2.3 Weight Initialization Weight initialization is a huge concern for neural networks . In this paper, the weights within a li”: are initiali' d such that F is a line across the link, the equation is give: as yy where wa is chosen with a uniform random distribution in the range . 2.4 Choosing Ranges rmin and rmax Choosing proper ranges for the links is key to getting good solutions. The weights used in the Lagrange polynomial interpolation do not mark the limits o except in the linear case. Figure 8 shows 5 Lagrange polynomials wi for weights within the desired range note that only in he values of the weights. Instead, if the weights are in the range then a given choice of weights will produce a maximum overshoot PpmaxWmax Where values of pymax are given in Table 2. For a given input, the maximum possible output would be pp. which could then be the input to the next link. The input range for each link shou © to account for these overshoots. One potential consec his choice of range is inpu ayer and one link passes through eac yetween 1 layer Wmar/TmarAfter passing t a consequence, the output from each layer is pushed towards the value 0 which means fewer and fewer of the ne is either side of 0 i and more of the su work sub links are used. Fortunately, two things can occur to situation: if a discontinuity is at the origin rapid learning can still occur since i just disconnected weights; as the network is trained, more will ac value decay. Consider a deep network with only one it will be compressed if rmax = Pnymax > Wmax by arough n layers, the output signal will be ” ' the polynomial value h maximum overshoot he linear case is the range limited by maxWmax d be set uence of unit per units. Each layer is initialized using Equation with wa = 1 and input range Suppose the input value is aj, then as the inp ut value he ratio Din. As help the a signal » links are used. It would seem randomly initializing the weights could alleviate this problem, however, we’ve found that symmetric initialization as in Equation works better. In this paper we use Tmax = —Tmin = Pn,max Where Pnrmax is provided in Table 2 which gives the maximum overshoot for the polynomials when the weights are constrained to be between 1 and -1. 13