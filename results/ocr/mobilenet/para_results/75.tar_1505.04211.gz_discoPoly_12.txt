DISCONTINUOUS PIECEWISE POLYNOMIAL NEURAL NETWORKS Table 2: Maximum overshoot fraction, Pn,max, given the number of points in the polynomial interpolation . 2.3 Weight Initialization Weight initialization is a huge concern for neural networks . In this paper, the weights within a lir" : are initiali d such that F is a line across the link, the equation is givei as where Wa is chosen with a uniform random distribution in the range . 2.4 Choosing Ranges Tmin and T'max Choosing proper ranges for the links is key to getting good solutions. The weights used in the Lagrange polynomial interpolation do not mark the limits of the polynomial value except in the linear case. Figure 8 shows 5 Lagrange polynomials with maximum overshoot for weights within the desired range note that only in the linear case is the range limited by the values of the weights. Instead, if the weights are in the range then a given choice of weights will produce a maximum overshoot Pr,maxWmax where values of Pn,max are given in Table 2. For a given input, the maximum possible output would be Pn,maxWmax which could then be the input to the next link. The input range for each link should be set to -Pusndnahuaabbna to account for these overshoots. One potential consequence of this choice of range is input value decay. Consider a deep network with only one unit per layer and one link between units. Each layer is initialized using Equation 0 with Wa = 1 and input range E Pr.max:Pr.max Suppose the input value is Tin then as the input value passes through each layer it will be compressed if Tmaz Pn,max > Wmaz by the ratio Wmaz/TmazAfter passing through T layers, the output signal will be "tam As a consequence, the output from each layer is pushed towards the value 0 which means fewer and fewer of the network sub links are used. Fortunately, two things can occur to help the situation: if a discontinuity is at the origin rapid learning can still occur since if a signal is either side of 0 it will adjust disconnected weights; as the network is trained, more and more of the sub links are used. It would seem randomly initializing the weights could alleviate this problem, however, we've found that symmetric initialization as in Equation 0 works better. In this paper we use Tmaz E Tmin Pn,max where Pn,max is provided in Table 2 which gives the maximum overshoot for the polynomials when the weights are constrained to be between 1 and -1. 13