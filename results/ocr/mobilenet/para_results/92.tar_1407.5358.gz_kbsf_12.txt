KBSF computational cost becomes a function of m only. In particular, the cost of solving M through dynamic programming becomes polynomial in m instead of T2: while one application of T, the Bellman operator of M,is O, the computation ofT is O. Therefore, KBSF's time and memory complexities are only linear in n. We note that, in practice, KBSF's computational requirements can be reduced even further if one enforces the kernels KZ and Rf to be sparse. In particular, given a fixed Si, instead of computing ke for j = 1,2,.,mas one can evaluate the kernel on a pre-specified neighborhood of Si only. Assuming that ke is zero for all s5 outside this region, one avoids not only computing the kernel but also storing the resulting values for a fixed 88. 4.1 A closer look at KBSF's approximation As outlined in Section KBRL defines the probability of a transition from state 8! to state 8% as being N2, where a,b € A . Note that the kernel K7 is computed with the initial state s, and not 8% itself. The intuition behind this is simple: since we know the transition sf 58 has occurred before, the more "similar" 3P is to 82 the more likely the transition 84 % 8 becomes . From , it is clear that the computation of matrices Ka performed by KBSF follows the same reasoning underlying the computation of KBRL's matrices pa; in particular, RE gives the probability of a transition from 8j to S2. However, when we look at matrix D things are slightly different: here, the probability of a "transition" from 80 to representative state Sj is given by R a computation that involves Sj itself. If we were to strictly adhere to KBRI's logic when computing the transition probabilities to the representative states 8j, the probability of transitioning from 8h to 8j upon executing action a should be a function of 8h and a state s' from which we knew a transition s' 3 5j had occurred. In this case we would end up with one matrix D" for each action a € A. Note though that this formulation of the method is not practical, because the computation of the matrices D" would require a transition 4 Sj for each a € A and each 8j € S. Clearly, such a requirement is hard to fulfill even if we have a generative model available In this section we provide an interpretation of the approximation computed by KBSF that supports our definition of matrix D. We start by looking at how KBRL constructs the matrices Pa, As shown in Figure 2a, for each action a € A the state 3P has an associated stochastic vector DE E Rixn whose nonzero entries correspond to the kernel K2 evaluated at S2,k 1,2,..-,1a Since we are dealing with a continuous state space, itis possible to compute an analogous vector for any 8 € S and any a € A. Focusing on the to generate sample transitions. nonzero entries of D, we define the function Clearly, full knowledge of the function Pga allows for an exact computation of KBRL's transition matrix Éa, Now suppose we do not know Pge and we want to compute an 13