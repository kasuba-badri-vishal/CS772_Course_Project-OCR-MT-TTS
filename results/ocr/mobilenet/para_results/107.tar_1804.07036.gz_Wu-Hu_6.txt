maries extracted by RNES are of higher quality than sumTable 2: Performance comparison on CNN/Daily Mail test set, evaluated with full-length F1 ROUGE scores . All scores of RNES are statistically significant using 95% confidence interval with respect to previous best models. or without coherence. The summary produced by RNES without coherence starts with pronoun That' which is referring to a previously mentioned fact, and hence it may lead to confusion. In contrast, the output of RNES trained with COherence reward includes the sentence "The earthquake disaster. ? before referring to this fact in the second sentence, and therefore is more coherent and readable. This is because the coherence model gives a higher score to the second sentence if it can form a coherent sentence pair with the first sentence. In REINFORCE training, if the second sentence receives a high coherence score, the action of extracting the first sentence before the second one will be strengthened. This example shows that coherence model is indeed effective in changing the behavior of RNES towards extracting maries produced by previous works. summaries that are more coherent. Table 4: Examples of extracted summary. Though RNES with the coherence reward achieves higher ROUGE scores than baselines, there is a small gap between its score and that of RNES trained without coherence model. This is because that the coherence objective and ROUGE score do not always agree with each other. Since ROUGE is simply computed based on n-grams or longest common subsequence, it is ignorant of the coherence between sentences. Therefore, enhancing coherence may lead to a drop of ROUGE. However, the 95% confidence intervals of the two RNES models overlap heavily, indicating that their difTable 3: Comparison of human evaluation in terms of informativeness, coherence and overall ranking. Lower ference in ROUGEI is insignificant. is hetter, We also conduct a qualitative evaluation to find out whether the introduction of coherence reward improves the coherence of the output summaries. We randomly sample 50 documents from the test set and ask three volunteers to evaluate the summaries extracted by RNES trained with or without coherence as the reward. They are asked to compare and rank the outputs of two models regarding three aspects: informativeness, coherence and overall quality. The better one will be given rank 1, while the other will be given rank 2 if it is worse. In some cases, if the two outputs are identical or have the same quality, the ranks could be tied, 1.e., both of them are given rank 1. Table 3 shows the results of human evaluation. RNES model trained with coherence reward is better than RNES model without coherence reward in all three aspects, especially in the coherence. The result indicates that the introduction of coherence effectively improves the coherence of extracted summaries, as well as the overall quality. It is surprising that summaries produced by RNES with coherence are also more informative than RNES without coherence, indicating that ROUGE might not be the gold standard to evaluate informativeness as well. Table 4 shows a pair of summary produced by RNES with Conclusion from a document. summary single In this paper, we proposed a Reinforced Neural Extractive Summarization model to extract a coherent and informative that the proposed RNES model can balance between the cross-sentence coherence and importance of the sentences effectively, and achieve state-of-the-art performance on the benchmark dataset. For future work, we will focus on improving the performance of our neural coherence model and introducing human knowledge into the RNES. This work is supported by grants from WeChat-HKUST Joint Lab on Artificial Intelligence Technology . Baotian Hu acknowledges partial support from the University of Massachusetts Medical School. Empirical results show Acknowledgments