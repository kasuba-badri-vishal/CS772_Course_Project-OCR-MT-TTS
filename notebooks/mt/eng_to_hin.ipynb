{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJ4QPLF61vIL",
    "outputId": "cceef3dd-0682-45bb-ad41-972e8b5e311f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXEBPd1U18Yo",
    "outputId": "2d705a93-3137-4af9-c283-abe5174fa2f1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/gdrive/My Drive/dataset\n"
     ]
    }
   ],
   "source": [
    "cd gdrive/My Drive/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TqoOKUwC2aYR"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data1 = pd.read_csv(\"source_test.txt\",sep='   ',header=None,names=['english_sentence'])\n",
    "data1.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imtjJ-_WWE3n",
    "outputId": "d6e17971-cffe-48b8-9b72-e4d908d62fa2"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-4-84e645969558>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data1 = pd.read_csv(\"source_test.txt\",sep='   ',header=None,names=['english_sentence'])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2507, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQjWbqYv3Tlu",
    "outputId": "61e4ef31-9c97-4d1b-c974-6ac9b5ee4ba7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-5-cef81c82a89c>:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data1 = pd.read_csv(\"source_test.txt\",sep='   ',header=None,names=['english_sentence'])\n",
      "<ipython-input-5-cef81c82a89c>:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data2 = pd.read_csv(\"target_test.txt\",sep='    ',header=None,names=['hindi_sentence'])\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# data = pd.read_csv('eng_hin_data.csv')\n",
    "data1 = pd.read_csv(\"source_test.txt\",sep='   ',header=None,names=['english_sentence'])\n",
    "data2 = pd.read_csv(\"target_test.txt\",sep='    ',header=None,names=['hindi_sentence'])\n",
    "# print(data)  \n",
    "# Separate the English and Hindi sentences\n",
    "eng_sentences = data1['english_sentence'][:1500]\n",
    "hin_sentences = data2['hindi_sentence'][:1500]\n",
    "\n",
    "# Tokenize the English and Hindi sentences\n",
    "eng_tokenizer = Tokenizer()\n",
    "eng_tokenizer.fit_on_texts(eng_sentences)\n",
    "hin_tokenizer = Tokenizer()\n",
    "hin_tokenizer.fit_on_texts(hin_sentences)\n",
    "\n",
    "# Vocabulary sizes\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "hin_vocab_size = len(hin_tokenizer.word_index) + 1\n",
    "\n",
    "# Maximum sentence lengths\n",
    "eng_max_len = max([len(sent.split()) for sent in eng_sentences])\n",
    "hin_max_len = max([len(sent.split()) for sent in hin_sentences])\n",
    "\n",
    "# Encode the English sentences\n",
    "eng_seq = eng_tokenizer.texts_to_sequences(eng_sentences)\n",
    "eng_seq = pad_sequences(eng_seq, maxlen=eng_max_len, padding='post')\n",
    "\n",
    "# Encode the Hindi sentences\n",
    "hin_seq = hin_tokenizer.texts_to_sequences(hin_sentences)\n",
    "hin_seq = pad_sequences(hin_seq, maxlen=hin_max_len, padding='post')\n",
    "\n",
    "# One-hot encode the Hindi sentences\n",
    "hin_onehot = to_categorical(hin_seq, num_classes=hin_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "h6QEu7Aeehh1",
    "outputId": "694eb142-1f36-4fc7-8533-85248689a085"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                       english_sentence\n",
       "0                              A black box in your car?\n",
       "1     As America's road planners struggle to find th...\n",
       "2     The devices, which track every mile a motorist...\n",
       "3     The usually dull arena of highway planning has...\n",
       "4     Libertarians have joined environmental groups ...\n",
       "...                                                 ...\n",
       "2502  It is noteworthy that both Nita and Isha are p...\n",
       "2503    250 VIPs have been invited to this royal party.\n",
       "2504  These include the Jodhpur royal family and Uma...\n",
       "2505  L.N. Mittal, Sachin Tendulkar, and Bollywood a...\n",
       "2506  32 chartered planes have been booked to ferry ...\n",
       "\n",
       "[2507 rows x 1 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-0684d451-ba2a-49cd-ba2f-27ec67624463\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A black box in your car?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As America's road planners struggle to find th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The devices, which track every mile a motorist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The usually dull arena of highway planning has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Libertarians have joined environmental groups ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>It is noteworthy that both Nita and Isha are p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>250 VIPs have been invited to this royal party.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>These include the Jodhpur royal family and Uma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>L.N. Mittal, Sachin Tendulkar, and Bollywood a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>32 chartered planes have been booked to ferry ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2507 rows Ã— 1 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0684d451-ba2a-49cd-ba2f-27ec67624463')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0684d451-ba2a-49cd-ba2f-27ec67624463 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0684d451-ba2a-49cd-ba2f-27ec67624463');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lJ--x9LL3VpT"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_input = Input(shape=(eng_max_len,))\n",
    "encoder_embedding = Embedding(eng_vocab_size, 256, mask_zero=True)(encoder_input)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_output, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_input = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(hin_vocab_size, 256)(decoder_input)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_output, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "# Attention\n",
    "attention = Attention()([decoder_output, encoder_output])\n",
    "\n",
    "# Concatenate the attention output and decoder output\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_output, attention])\n",
    "\n",
    "# Output\n",
    "decoder_dense = Dense(hin_vocab_size, activation='softmax')\n",
    "output = decoder_dense(decoder_concat)\n",
    "\n",
    "# Model\n",
    "model = Model([encoder_input, decoder_input], output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5Dnikah3i3y"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "results=model.fit([eng_seq, hin_seq[:, :-1]], hin_onehot[:, 1:], epochs=100, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOFBGdeaIkTx"
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = results.history['acc']\n",
    "# val_acc = results.history['val_accuracy']\n",
    "loss = results.history['loss']\n",
    "# val_loss = results.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training accuracy')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.savefig('wordA.png')\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'o', label='Validation loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend(loc=0)\n",
    "plt.savefig('wordL.png')\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Add the 'start' token to the Hindi tokenizer's word index\n",
    "hin_tokenizer.word_index['start'] = hin_vocab_size + 1\n",
    "hin_tokenizer.word_index = {k: v + 1 for k, v in hin_tokenizer.word_index.items()}\n",
    "hin_tokenizer.word_index[''] = 0\n",
    "hin_tokenizer.word_index['start'] = hin_vocab_size + 1\n",
    "\n",
    "# Update the Hindi vocabulary size\n",
    "hin_vocab_size = len(hin_tokenizer.word_index) + 1\n",
    "\n",
    "# Add the empty string token to the Hindi tokenizer's word index\n",
    "hin_tokenizer.word_index[''] = 0\n",
    "hin_tokenizer.word_index = {k: v + 1 for k, v in hin_tokenizer.word_index.items()}\n",
    "\n",
    "# Update the Hindi vocabulary size\n",
    "hin_vocab_size = len(hin_tokenizer.word_index) + 1\n"
   ],
   "metadata": {
    "id": "Rr662gkHki0i"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Add the empty string token to the Hindi tokenizer's word index\n",
    "hin_tokenizer.word_index[''] = 0\n",
    "hin_tokenizer.word_index = {k: v + 1 for k, v in hin_tokenizer.word_index.items()}\n",
    "\n",
    "# Update the Hindi vocabulary size\n",
    "hin_vocab_size = len(hin_tokenizer.word_index) + 1\n",
    "\n",
    "def generate_translation(input_sentence):\n",
    "    # Convert the input sentence to a sequence of integers\n",
    "    input_sequence = eng_tokenizer.texts_to_sequences([input_sentence])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=eng_max_len, padding='post')\n",
    "\n",
    "    # Initialize the target sequence with the 'start' token\n",
    "    target_sequence = np.zeros((1, hin_max_len))\n",
    "    target_sequence[0, 0] = hin_tokenizer.word_index['start']\n",
    "\n",
    "    # Generate the translation one token at a time\n",
    "    for i in range(1, hin_max_len):\n",
    "        # Predict the next token in the target sequence\n",
    "        prediction = model.predict([input_sequence, target_sequence]).argmax(axis=2)\n",
    "        target_sequence[0, i] = prediction[0, i-1]\n",
    "\n",
    "        # If the predicted token is the 'end' token, end the translation\n",
    "        hin_word = hin_tokenizer.index_word.get(target_sequence[0, i])\n",
    "        if hin_word is None or hin_word == 'end':\n",
    "            break\n",
    "\n",
    "    # Convert the target sequence to a sequence of words\n",
    "    hin_words = []\n",
    "    for i in range(1, hin_max_len):\n",
    "        hin_word = hin_tokenizer.index_word.get(target_sequence[0, i], None)\n",
    "        if hin_word is None or hin_word == 'end':\n",
    "            break\n",
    "        hin_words.append(hin_word)\n",
    "\n",
    "    # Convert the sequence of words to a string and return it\n",
    "    return ' '.join(hin_words)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "pvgxNRSggaRm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "# Test the model on some sample English sentences\n",
    "test_sentences = [\n",
    "    'I love eating pizza.',\n",
    "    'The cat is sleeping on the sofa.',\n",
    "    'What time is it?',\n",
    "    'I have to go now.',\n",
    "    'This is a nice surprise!',\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    translation = generate_translation(sentence)\n",
    "    print(f'{sentence} => {translation}')"
   ],
   "metadata": {
    "id": "FvsOJcnekIM2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "XBqCWbGBosfA"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
